mode: e2e
data:
  dataset:
    name: locnarr
    dataset_root: /media/exx/HDD/zhenyulu/data/coco
    text_file: Flickr8k.token.txt
    clip_image_transform: ViT-B/32
    load_image: true
    load_audio: true
    tokenizeText: true
    modalities: ["audio", "image", "text"]
  batch_size: 64
  dev_batch_size: 4
  split_ratio: 0.9

model_settings:
  modality: ["audio", "image"] #, "text"]
  audio_branch: 
    projection_type: MHA # linear
  text_branch:
    projection: False
    projection_type: Linear # linear
  image_branch: 
    projection: False
    projection_type: Linear # linear
  transformer_type: MultiheadAttentionAndNorm #TransformerEncoder
  transformer_args:
      n_layers: 1
      d_model: 768
      nhead: 8
      dim_feedforward: 3072
      dropout: 0.1
      activation: gelu
      layer_norm_eps: 1.0e-5
      batch_first: True
      norm_first: False
  need_projection: true
  
cl_loss:
  type: MaskedContrastiveLoss # SupConLoss
  args:
    temperature: 0.07
    temperature_trainable: False
    margin: 0.0
    dcl: false
    a2b:  true
    b2a: true

    # for SupConLoss
    # temperature: 1.0
    # base_temperature: 1.0
    # contrast_mode: all
    # learnable_temperature: true
retrieval:
  audio_feat_src: parallel  # ["parallel","cascaded"]
  recall_at: [1,5,10]

clip:
  name: ViT-B/16 
  prompt: True
  design_details:
    trainer: 'MaPLe' #None
    vision_depth: 0
    language_depth: 0 
    vision_ctx: 0
    language_ctx: 0
    maple_length: 2
    compound_prompts_depth: 2


audio_encoder:
  type: FairseqHubert
  name: hubert
  pretrained: true
  trainable: false
  feat_select_idx: weighted_sum #last_hidden_state # all
  layer_drop: 0.0
  max_audio_len: 102400
  normalize_hiddenstates: false
  optim:
    name: Adam
    args:
      lr: 1.e-4
      weight_decay: 1.e-6
  scheduler:
    name: linear_warmup_decay
    warmup: 5000
    max_step: 50000
    final_lr: 1.e-8

trainer:
  max_steps: 50000
  gradient_clip_val: 4
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 10
  precision: 16
  #logger: wandb
  # log_every_n_steps: 8
  # default_root_dir: exp/sphclip_base_p_flickr
  # num_sanity_val_steps: 0
  # strategy: dp
  # limit_train_batches: 8
  # limit_val_batches: 8

log_setting:
  log_detokenize_results: true # whether or not to save the results of detokenized vq output
  log_detokenize_results_every_n_epoch: 5
  log_draw_pca_every_n_epoch: 10

logger:
  project: sphclip
