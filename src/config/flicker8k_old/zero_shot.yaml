mode: asr
data:
  dataset:
    name: flickr8k
    dataset_root: /media/exx/HDD/zhenyulu/flickr
    text_file: Flickr8k.token.txt
    clip_image_transform: ViT-L/14
    load_image: true
    load_audio: true
    tokenizeText: true
    modalities: ["audio", "image", "text"]
  batch_size: 4
  dev_batch_size: 64
  split_ratio: 0.9

model_settings:
  modality: ["audio", "image"]
  audio_branch: 
    projection_type: Linear # linear
  text_branch:
    projection: false
    projection_type: Linear # linear
  image_branch: 
    projection: false
    projection_type: Linear # linear
  transformer_type: MultiheadAttentionAndNorm #TransformerEncoder
  transformer_args:
      n_layers: 1
      d_model: 768
      nhead: 8
      dim_feedforward: 3072
      dropout: 0.1
      activation: gelu
      layer_norm_eps: 1.0e-5
      batch_first: True
      norm_first: False
  need_projection: true
  
cl_loss:
  type: MaskedContrastiveLoss # SupConLoss
  args:
    temperature: 0.07
    temperature_trainable: False
    margin: 0.0
    dcl: false
    a2b:  true
    b2a: true

    # for SupConLoss
    # temperature: 1.0
    # base_temperature: 1.0
    # contrast_mode: all
    # learnable_temperature: true
retrieval:
  recall_at: [1,5,10]

clip:
  name: ViT-L/14
  prompt: false
  design_details:
    trainer: 'None'
    vision_depth: 0
    language_depth: 0 
    vision_ctx: 0
    language_ctx: 0
    maple_length: 2
    compound_prompts_depth: 8


ASR:
  type: Whisper
  name: base.en

trainer:
  max_steps: 50000
  gradient_clip_val: 4
  accumulate_grad_batches: 1
  check_val_every_n_epoch: 1
  precision: 16
  #logger: wandb
  # log_every_n_steps: 8
  # default_root_dir: exp/sphclip_base_p_flickr
  # num_sanity_val_steps: 0
  # strategy: dp
  # limit_train_batches: 8
  # limit_val_batches: 8

log_setting:
  log_detokenize_results: true # whether or not to save the results of detokenized vq output
  log_detokenize_results_every_n_epoch: 5
  log_draw_pca_every_n_epoch: 10

logger:
  project: sphclip
